[{"title":"ctp登录、查询","url":"/yukizzc.github.io/2024/07/24/ctp1/","content":"\n# 登录\n\nSpi （如 CThostFtdcTraderSpi），包含有所有的响应和回报函数，用于接收综合交易平台发送或交易所发送 综合交易平台转发的信息。开发者需要继承该接口类，并实现其中相应的虚函数\n\nApi （如 CThostFtdcTraderApi），包含主动发起请求和订阅的接口函数，开发者直接调用即可\n\n上面是官方文档中的介绍，我们使用时候就是创建api和spi的实例对象即可。所有动作额执行都是通过api发送请求出去，然后ctp柜台接到请求把处理结果通过spi的回调函数返回给客户端，我们的实现逻辑就是重写这些回调函数\n\n## **ctp准备工作**\n\n1、创建api实例\n\n2、创建spi实例\n\n3、把spi对象注册进api中\n\n4、设置前置交易地址，订阅公有流和私有流\n\n5、初始化函数Init()，调用后,接口才开始发起前置的连接请求\n\n```python\ntraderapi = tdapi.CThostFtdcTraderApi_CreateFtdcTraderApi()\ntraderspi = CTraderSpi(traderapi)\ntraderapi.RegisterSpi(traderspi)\ntraderapi.RegisterFront(login_info['Trade Front'])\ntraderapi.SubscribePrivateTopic(tdapi.THOST_TERT_QUICK)\ntraderapi.SubscribePublicTopic(tdapi.THOST_TERT_QUICK)\ntraderapi.Init()\n```\n\n上面是python的程序，其中CTraderSpi自建的类\n\n## **ctp登录流程**\n\n1、OnFrontConnected：初始化链接后响应函数，然后这里去执行api.ReqAuthenticate\n\n2、OnRspAuthenticate：客户端认证回调，在里面再去执行登录动作api.ReqUserLogin\n\n3、OnRspUserLogin：登录响应，每天第一次需要确认结算单，这里再去执行api.ReqSettlementInfoConfirm\n\n4、OnRspSettlementInfoConfirm：结算确认响应，这一步其实不需要，到这一步ctp内部的登录流程就走完了\n\n## **属性说明**\n\n1、GetTradingDay：这个是api中自带的方法，通过它可以返回当前交易日，对于夜盘晚上会返回下个交易日，如当天是否确认结算单等就可以靠这个来标记\n\n2、FrontID, SessionID：这两个属性在OnRspUserLogin回报中返回，分别是前置编号和会话编号，其中后者每次重新登录都会不同并且是递增的。许多人撤单会使用 FrontID + SessionID + OrderRef 撤单的方式，不过我个人喜好第二种方式不使用这两个ID而是采用柜台实际编号的方式，具体后面下单环节再细说。我自己目前只是把这两个ID加上前面的交易日组合成本地初始的OrderRef来使用，后续下单时候从OrderRef这个字段读取然后自增1，其他地方没怎么使用\n\n\n\n总体来说ctp登录账户还是比较简单的，可以看到就是一个api函数，然后spi中受到回报进行处理，其实整个ctp的所有操作都是这样一个流程，只要把握好回调函数中各种数据属性及自己本地的落地如何保存就行了\n\n# 查询\n\nctp中有所谓流控机制，有分为报单流控、查询流控等。报单流控一般不会触发，至少一秒几笔还是可以达到的，但是查询流控就比较恶心\n\n自从穿透式监管版本以后，API在连接交易前置时，会去查询到前置的查询流控设置（该设置配置在front_se组件）。假设前置配置了2笔/秒，那么连接该前置的API每秒只能发起2笔查询请求。\n\n但是要注意，不管怎么配置，API都内置了在途流控，在途查询流控为1笔。即，当前这笔查询请求发出后，在未收完所有的查询响应前，不能发起下一笔查询请求。\n\n在过去，查询流控是内置在API里，1笔每秒，在途1笔。\n\n如果超过交易前置配置的查询流控，则会触发OnRspError，并提示：“CTP：查询未就绪，请稍后重试”\n\n如果超过API内置的在途流控，则查询请求的返回值为-2，表示未处理请求超过许可数。\n\n以上是官方文档中的说明，可以看到是没办法支持连续查询的，所以对于偏高频多品种同时交易，成交后去查询持仓这个操作是一定会触发流控的。解决方法可以在返回值非0时候扔到一个队列中，外面专门开一个线程去队列里取值再次查询，或者建立一个while的循环，连续循环比如10次，每次返回失败延迟1秒再去查，查询成功跳出循环结束执行\n\n个人目前是采用第二种方案，然后在报单成交后查持仓这个动作是直接通过队列专门查询的，以防止查持仓这个动作的延迟影响整个回报函数中接受信息的延迟\n\n## **查持仓**\n\n通过查询函数ReqQryInvestorPosition执行后，回调函数OnRspQryInvestorPosition返回持仓信息，ctp的返回是一条记录一条记录的返回的，对于上期的话今仓和老仓是算作两条持仓分别返回\n\nReqQryInvestorPosition这个函数的参数结构中如果带上品种合约，则会返回该品种的持仓，如果不设置品种合约，则返回所有持仓合约\n\n下面重点看下回调函数的返回值\n\nPositionDate：持仓日期，‘1’表示当前交易日持仓    ‘2’表示是历史仓（只有上期和能源有这个值）\n\nPosiDirection：是枚举值，'2'表示多头持仓   '3'表示空头持仓\n\n通过这两个属性就能知道当前品种的仓位情况，所以本地构建数据结构名时候就需要根据这两个进行处理。个人使用的方法是把这两个属性相在加上品种代码就得到对应的持仓名称，PositionDate+PosiDirection+InstrumentID\n\n比如：12:rb2410就可以表示螺纹钢10合约的多头今仓\n\n除上期所品种: 12表示多头持仓，13表示空头持仓\n\n上期所品种: 12表示多头今天仓，13表示空头今天仓，22表示多头老仓，23表示空头老仓\n\n而头寸的具体信息这边保存字典格式如下\n\n```python\ndict_ = {\n        '总持仓': pInvestorPosition.Position,\n        '今持仓': pInvestorPosition.TodayPosition,\n        '持仓盈亏': pInvestorPosition.PositionProfit,\n        '多头冻结': pInvestorPosition.LongFrozen,\n        '空头冻结': pInvestorPosition.ShortFrozen,\n        '保证金': pInvestorPosition.UseMargin,\n        '持仓成本': pInvestorPosition.PositionCost,\n        '开仓成本': pInvestorPosition.OpenCost\n\t\t}\n```\n\n对于上海的品种，老仓下只有Position没有TodayPosition，而今仓下Position和TodayPosition是相等的\n\n对于非上海品种，Position就是总的持仓，而TodayPosition就表示今仓\n\n所以我们平仓时候判断持仓直接去读Position就可以了，一般不用理会今仓\n\n多头冻结和空头冻结：这两是挂单的意思\n\n对于多头持仓，多头冻结就是开仓未成交，空头冻结是平多未成交\n\n对于空头持仓，空头冻结是开空未成交，多头冻结是平空未成交\n\n所以要计算实际可平数量时候需要根据对应关系自己做好减去冻结的逻辑关系，比如判断可用多头就要用Position-ShortFrozen，实际持仓-对应的平仓挂单\n\n## **查帐户资金**\n\n通过查询函数ReqQryTradingAccount执行后，回调函数OnRspQryTradingAccount返回账户的资金情况\n\n账户的字段解释如下\n\n```python\ndict_ = {\n        '持仓盈亏': pTradingAccount.PositionProfit,\n        '平仓盈亏': pTradingAccount.CloseProfit,\n        '手续费': pTradingAccount.Commission,\n        '保证金总额': pTradingAccount.CurrMargin,\n        '可用资金': pTradingAccount.Available,\n        '权益': pTradingAccount.Balance,\n        '昨权益': pTradingAccount.PreBalance\n\t\t}\n```\n\n\n\n# \n","tags":["ctp"],"categories":["finance"]},{"title":"pandas","url":"/yukizzc.github.io/2024/07/24/pandas/","content":"\n```python\nimport numpy as np\nimport pandas as pd\n```\n\n```python\n# 展示所有行，None可以改成具体限制数量\npd.set_option('display.max_rows', None)\n# 展示所有列，None可以改成具体限制数量\npd.set_option('display.max_columns', None) \n```\n\n# 创建pandas\n\n```python\n# 通过字典创建\ndic = {'name':['liu','guoli'],'age':[32,33]}\ndf = pd.DataFrame(dic)\n```\n\n```python\n# array创建\narray1 = np.random.randint(low=2,high=100, size=(2, 4))\ndf = pd.DataFrame(array1,index=[1,2],columns=['a','b','c','d'])\n```\n\n```python\n# 把seires转换成dataframe\ndf_series = pd.Series(np.random.randint(0,100,size=(10)),\n                        index=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\ndf = pd.DataFrame(df_series, columns=['A'])\n```\n\n```python\n# DataFrame的append方法\naccount_log = pd.DataFrame(columns=['date', '动态权益', '保证金/市值'])\nvalue = {'date': 1,\n         '动态权益': 2,\n         '保证金/市值': 3\n        }\naccount_log.loc[len(account_log)] = pd.Series(value)\n# 如果对效率有要求就不要这么添加，直接用字典添加数据最后转换df格式\naccount_log = {i: [] for i in ['date', '动态权益', '保证金/市值']}\nvalue = [1,2,3]\n\nfor i, j in zip(account_log, value):\n    account_log[i].append(j)\nvalue = [4,5,6]\nfor i, j in zip(account_log, value):\n    account_log[i].append(j)\npd.DataFrame(account_log)\n```\n\n```python\n# 循环输出每一行\ndf = pd.DataFrame([[1,2],[3,4],[5,6]],index=['a','b','c'],columns=['L1','L2'])\nfor index_,vlaue_ in df.iterrows():\n    print(index_)\n    print(vlaue_.to_dict())\n    print(vlaue_.values)\n```\n\n\n\n# 常用属性\n\n```python\nboolean=[True,False]\ngender=[\"男\",\"女\"]\ncolor=[\"white\",\"black\",\"yellow\"]\ndata=pd.DataFrame({\n    \"height\":np.random.randint(150,190,20),\n    \"weight\":np.random.randint(40,90,20),\n    \"smoker\":[boolean[x] for x in np.random.randint(0,2,20)],\n    \"gender\":[gender[x] for x in np.random.randint(0,2,20)],\n    \"age\":np.random.randint(15,90,20),\n    \"color\":[color[x] for x in np.random.randint(0,len(color),20) ]\n}\n)\n```\n\n```python\n# 根据列名取数据,第一个参数是index的值\ndata.loc[[0,1],['height','age']]\n# iloc方法使用整数索引，也即第几个\n# 这个是组合使用，第三行字段是height所在数据\ndata.iloc[3,df.columns.get_loc('height')]\n```\n\n```python\n# 重置index序号\ndata_gen = data[data['gender']=='男'].reset_index()\n```\n\n```python\n# 根据位置序号取数据\ndata.iloc[0:4,2:5]\n```\n\n```python\n#属性\ndata.columns,data.index,data.shape\n```\n\n```python\n# 返回array数据\ndata.values\n```\n\n```python\n# 头尾展示\ndata.head(3),data.tail(2)\n```\n\n```python\n# 统计信息\ndata.count()\n```\n\n```python\n# 详细信息\ndata.info()\n```\n\n```python\n# 数值类型的描述\ndata.describe()\n```\n\n```python\n# 非数值类型的描述\ndata.describe(include=object)\n```\n\n```python\n# 列累加\ndata.cumsum()\n```\n\n```python\n# 列相减\ndata.loc[:,['height','age']].diff(periods=1)\n```\n\n```python\n# 相关系数\ndata.corr()\n```\n\n```python\n#统计某列数据分布（数值和对应的数量）\ndata['color'].value_counts()\n```\n\n```python\n#枚举某一列 \ndata['color'].unique() \n```\n\n# 方法\n\n```python\n#删除指定字段里有None的行\ndf.dropna(subset=['sales_depart_name'],inplace=True)\n#某个字段里包含某个字符的筛选数据\ndf[df.sales_depart_name.str.contains('包含的字符')]\n```\n\n```python\n# 某个字段后一项减前项差值，可填参数\ndf['height'].diff()\n# 当前元素与先前元素的相差百分比，这两个用来做收益率很有用\ndf['heightd'].pct_change()\n```\n\n```python\n#筛选某列数值属于某个列表范围内\ndata[data['color'].isin(['yellow','white'])]\n```\n\n```python\n# 根据布尔值筛选数据\ndata[data['gender']=='男']\n# 组合条件\ndata[(data['gender']=='男') & (data['height']>160)]\n# 用query筛选\ndata_query = data.query(\"age < 30 and color=='white'\")\ndata_query.head()\n```\n\n```python\n#返回每个元素在当前列的排名，从小到大\ndata.rank()  \n```\n\n```python\n#根据列进行排序,ascending=False表示降序\ndata.sort_values(by=['height', 'weight'],ascending=False) \n```\n\n```python\n#修改index\ndata2 = data.reindex(index=np.arange(len(data))[::-1])\n```\n\n```python\n# 重置index\ndata2.reset_index(inplace=True)\n```\n\n```python\n# 删除某列\ndel data2['index']  \n```\n\n```python\n#删除指定列或行，axis删除列。inplace表示替换原数据      \ndata.drop(['height','weight'],axis=1,inplace=True) \n```\n\n```python\n# 改变某列数据类型\ndf['date'] = df['date'].astype('str')\n# 把字符串转换成日期格式，日期可以进行排序\ndf = pd.DataFrame([['2019-05-30',1],['2020-06-30',2],['2018-06-30',2]],columns=['date','num'])\ndf['date_str'] = pd.to_datetime(df['date'])\ndf.sort_values(by='date_str')\n```\n\n```python\n# 写入多个sheet\nexcel_writer = pd.ExcelWriter(\"lll.xlsx\")\n#有了ExcelWriter对象后就可以在一个工作簿中写入多张表数据了\ndf1.to_excel(excel_writer,sheet_name=\"概念板块资金流向\")\ndf2.to_excel(excel_writer,sheet_name=\"A股资金流向\")\n#一定要关闭excel文档，不然可能报错\nexcel_writer.close()\n```\n\n# map方法\n\n```python\n#使用字典进行映射\ndata[\"gender\"] = data[\"gender\"].map({\"男\":1, \"女\":0})\n```\n\n```python\n#使用函数\ndef age_map(x):\n    gender = x if x >50 else 50\n    return gender\n#注意这里传入的是函数名，不带括号\ndata[\"age\"] = data[\"age\"].map(age_map)\n# lambda写法\ndata[\"age\"] = data[\"age\"].map(lambda x:(x if x>50 else 50))\n```\n\n# 聚合groupby\n\n```python\nimport pandas as pd\ndic = {'name':['liu','guoli','liu','guoli','guoli'],\n       'age':[32,33,34,35,36],\n       'local':['广东','韶关','韶关','深圳','广东'],\n       'height':[160,160,155,140,130]}\ndf = pd.DataFrame(dic)\n# 根据name进行分组\ngroup = df.groupby(by='name')\n# 根据name和local进行分组\ngroup2 = df.groupby(by=['name','local'])\n```\n\n|     | name  | age | local | height |\n| --- | ----- | --- | ----- | ------ |\n| 0   | liu   | 32  | 广东    | 160    |\n| 1   | guoli | 33  | 韶关    | 160    |\n| 2   | liu   | 34  | 韶关    | 155    |\n| 3   | guoli | 35  | 深圳    | 140    |\n| 4   | guoli | 36  | 广东    | 130    |\n\nGroupby简单来讲就是实现数据的快速分组聚合（求和、求均值等计算），比如按照name、local等进行数据的均值（和值）计算等\n\n```python\n# 求均值\ngroup['age'].mean()\n# 方差\ngroup['age'].std()\n# transform 通常与 groupby 结合使用，用于将函数应用于每个组的数据，\n# 并将结果广播回原始 DataFrame，保持数据的原始形状\ndf['name_age_mean'] = group['age'].transform('mean')\n# 根据名字分组，然后每组内做age差值，差值后可以把该差值再前移到当前行\n# 金融分析中未来收益率就这么算可以\ndf['差值'] =df.groupby('name')['age'].diff(1)\ndf['差值2'] = df.groupby('name')['差值'].shift(-1)\ndf\n```\n\n|     | name  | age | local | height | name_age_mean |\n| --- | ----- | --- | ----- | ------ | ------------- |\n| 0   | liu   | 32  | 广东    | 160    | 33.000000     |\n| 1   | guoli | 33  | 韶关    | 160    | 34.666667     |\n| 2   | liu   | 34  | 韶关    | 155    | 33.000000     |\n| 3   | guoli | 35  | 深圳    | 140    | 34.666667     |\n| 4   | guoli | 36  | 广东    | 130    | 34.666667     |\n\n# 数据合并concat merge\n\n[pandas 的拼接merge和concat函数小结 - 亚北薯条 - 博客园 (cnblogs.com)](https://www.cnblogs.com/laiyaling/p/11798046.html)\n","tags":["python","数据分析"],"categories":["IT"]},{"title":"Hello World","url":"/yukizzc.github.io/2024/07/24/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]